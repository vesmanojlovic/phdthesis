\chapter{Agent-based workflow for inferring evolutionary parameters from molecular data using approximate Bayesian computation}\label{chapter:methdemon}


\section{Introduction}
In chapter \ref{chapter:trajectories}, I used a general agent-based model to investigate broad evolutionary
patterns as related to spatial organisation. While the model was capable of simulating the dynamics of
tumour growth, its utility is limited by the computational cost of simulating a large number of cells. This means
that using the model's outputs in comparison to or to draw inference from real data is not feasible. \par
There are a few ways to address this issue. For example, rather than simulating all clones in a tumour, one
could take the approach of \cite{sottoriva_big_2015} and use demes (tumour glands) as the principal agent of our
simulation. This would allow for a realistically-sized tumour to be generated as the number of glands would
be around the right order of magnitude. A problem with this approach is that it loses resolution since a
gland's population is assumed to be clonal, undergoing rapid fixation in the case of an emerging mutant. If one wanted to
study evolutionary dynamics on a finer scale it would be necessary to at least simulate the dynamics of cell
lineages, if not individual cells, as performed earlier. \par
In \cite{gabbutt_evolutionary_2023}, the authors employ a stochastic model for an expanding cell population
to model the behaviour of fluctuating CpG sites in blood cancers. The model is capable of simulating the
dynamics and the corresponding fluctuating methylation arrays of lymphoid malignancies at scale. However,
this model is not spatially explicit, which is a feature that has to be distinguished between different
glands in a solid tumour. In this chapter, I present a purpose-written agent-based model, \texttt{methdemon},
which reduces the computational cost of simulating a tumour's growth and models the fluctuating
methylation arrays in colorectal cancer.


\section{Background on colorectal cancer --- model assumptions}

\subsection{Colorectal cancer evolution}\label{section:assumptions:general}

The most common type of colorectal cancer is adenocarcinoma, which arises from the epithelial cells lining
the colon, covering more than $90\%$ of cases. Most diagnosed
colorectal cancers are moderately to well differentiated, meaning that at least $50\%$ of the tumour's cells
form glands \cite{fleming_colorectal_2012}.
As it is a solid tumour, one cannot ignore the spatial organisation of the cells. Its
origin, tumorigenesis, follows an accumulation of mutations in a cell's DNA, which leads to the cell's transformation
from a healthy to malignant cell \cite{fearon_genetic_1990}. Once the malignancy is established, the tumour
forms hierarchical cell structures similar to those of normal tissue \cite{cernat_colorectal_2014}, organising
into crypt-like glands. The tumour spreads by the process of gland fission, which happens when a gland's
population grows large enough to split into two glands \cite{preston_bottom-up_2003}. \par
Translated into the language of an agent-based model, I can write down the initial assumptions as follows:
\begin{enumerate}[(i)]
    \item \textbf{A single cell forms the first gland and initiates tumour growth.} This assumption skips
        over the process of tumorigenesis, during which a cell accumulates mutations and becomes
        malignant \cite{tariq_colorectal_2016}. This is a simplification to be sure, but a reasonable one,
        given that the focus of this work is on the evolutionary dynamics of the tumour rather than its
        initiation.
    \item \textbf{The rate of driver mutations is Poisson distributed and identical for all cells.} This
        assumption is consistent with most models of tumour evolution \cite{niida_modeling_2021}.
    \item \textbf{The cell population within a gland grows exponentially and is well-mixed.} While not necessarily
        consistent with the biology of a solid tumour, this assumption allows for more efficiency in the simulation
        as opposed to a multi-level spatial model. Further, as the data discussed in chapter \ref{chapter:methylation}
        is obtained from bulk samples of tumour glands, this assumption is not unreasonable. \label{item:well_mixed}
    \item \textbf{Once a gland reaches a certain size, which we call the carrying capacity, the population undergoes
        steady-state turnover according to the Moran process.}
    \item \textbf{At carrying capacity, a gland has a certain probability of undergoing fission, which splits the
        gland's population randomly into two.} As a consequence of assumption (\ref{item:well_mixed}), fissions do not
        take into account a gland's spatial organisation.
    \item \textbf{Gland fission occurs as a neutral spatial branching process.} The previous two assumptions and this
        one together form the basis of the model's spatial dynamics. While there are other mechanisms of colorectal
        adenocarcinoma progression, gland fission is the principal way in which the tumour grows \cite{preston_bottom-up_2003}.
        The assumption of neutrality in the spatial branching process is consistent with the findings of \cite{sottoriva_big_2015}.
\end{enumerate}

\subsection{Fluctuating methylation arrays}
As mathematicians new to biology quickly learn, perfectly clean data containing detailed information
about the population structure of a tumour is non-existent. In fact, most data is noisy and at best measures
a decent proxy for the properties which can be described by a mathematical model.
Therefore, one learns very quickly to improvise and adapt when working with biological data. Specifically, when it comes to
cancer, a compromise has to be made between resolution and scale. Where single-cell data can provide a detailed view of the
mutations accumulated in the genome, it is not feasible to obtain it for a whole tumour. On the other hand, bulk data
gives a high-level view of the tumour's population structure, but a lot of the details get lost in the process. \par
However, DNA sequencing is not the only way to obtain information about a tumour's population structure. Early work with
methylation arrays in colorectal cancer has shown potential for inferring the ancestry and age of a tumour \cite{hong_using_2010,
siegmund_high_2011}. In a way the genome shows more mutations in older populations, methylation arrays will also be more diverse
as time goes on. Current techniques allow for the sequencing of some $850,000$ CpG sites which, while a small fraction of the
genome, is still enough to proide valuable insight into the underlying dynamics of the cell population. Initial studies on
methylation as a tracker of evolutionmade use of the whole array \cite{siegmund_modeling_2008, sottoriva_integrating_2010}.
However, more recent work has shown that just a small subset of CpG sites is enough to infer the evolutionary dynamics of a
cell population \cite{gabbutt_fluctuating_2022, gabbutt_evolutionary_2023}. This is the set of fluctuating CpG (fCpG) loci,
which is also the topics of chapter \ref{chapter:methylation}. \par
On top of the assumptions outlined in section \ref{section:assumptions:general}, I include the following set for the modelling
of fluctuating methylation arrays:
\begin{enumerate}[(i')]
    \item \textbf{Each cell has a corresponding fCpG array inherited from its parent cell.}
    \item \textbf{Upon cell division, each methylated fCpG site has an independent and equal probability of being demethylated,
        and vice-versa.}
    \item \textbf{The rates of methylation and demethylation do not change over time.}
\end{enumerate}
These assumptions are based on the findings of \cite{gabbutt_fluctuating_2022, gabbutt_evolutionary_2023}.

\section{Existing simulation workflows}\label{section:old_famework}

With the assumptions outlined in the previous section, my initial approach was to employ a general agent-based model
with small modifications, due to the specific data type but broad evolutionary questions. The model I considered was
\texttt{demon}, with which I had already worked in chapter \ref{chapter:trajectories}. A naive approach to simulating
methylation arrays is to use the model's passenger mutations as a proxy for epigenetic changes. This way, the model
could be run as usual with modified passenger mutation rates, and the methylation arrays could be assigned to the
cells post-hoc. The main issue with this approach is memory management, as the output files tend to be large and
difficult to handle by the R compiler in the post-processing steps. By reconstructing the full passenger tree for each
clone, and assigning each mutation a random change of fCpG state, it is technically possible to obtain a synthetic data
for the system of interest. However, with simulations taking hours to run for a single tumour, and inefficient read
and write speeds, I abandoned this approach in favour of developing a more efficient one.

\textbf{TO DO: discuss the shortcomings of the old approach.}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Chapter_4/figures/old_workflow1.png}
    \caption{The old workflow for simulating tumour growth and assigning methylation arrays.}
    \label{fig:old_workflow1}
\end{figure}
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Chapter_4/figures/old_workflow2.png}
    \caption{The old workflow for simulating tumour growth and assigning methylation arrays.}
    \label{fig:old_workflow2}
\end{figure}


\section{A one-dimensional ABM of fluctuating methylation arrays in colorectal cancer}\label{section:methdemon}


\subsection{Overview}
\begin{itemize}
    \item go over the simulation's inner workings
    \item sensitivity analysis
    \item provide estimates of running efficiency and memory requirements
    \item discuss possible upgrades and their potential computational costs
\end{itemize}

For the specific case of multi-site sequencing of methylation arrays in colorectal cancer, I wrote
a C++ agent-based model, \texttt{methdemon}. The model is one-dimensional in space, as it does not
keep track of the exact spatial positions of the glands it simulates, only of the ``side" of the
tumour the gland is on --- left or right. The model assumes each cell in the simulation has an
infinite proliferative potential, and that the rate of driver mutations is constant. Further, gland
fissions can only occur once a gland has reached its carrying capacity, and all but the first fission
assume that the daughter glands will be on the same side of the tumour. The maximum number of glands
allowed by the model is $8$, which is the number of sampled glands per tumour in the data used in
chapter \ref{chapter:methylation}. \par
The model is scheduled according to the Gillespie algorithm \cite{gillespie_exact_1977}, with the
unit of time being the expected time for a cell to divide. All parameters are given in units of per
cell per cell division. The event hierarchy is structured the same as in \texttt{demon}, with the
addition of methylation events having a probability to happen at each fCpG site at each cell division.

\subsection{Sensitivity analysis}
\begin{itemize}
    \item list and explain the parameters used in the model (can ignore the ones not yet used)
    \item briefly explain the snakemake workflow used to run the model a bunch of times
    \item discuss the results of the sensitivity analysis for the parameters:
    \begin{itemize}
        \item carrying capacity - lower carrying capacity means higher probability of neutral
            fixation
        \item fission rate - higher fission rate means earlier divergence of glands and more
            time spent in independent turnover so very different arrays at the end of the
            simulation; conversely, lower fission rates lead to a more recent split and thus
            more closely related arrays
        \item mutation rate - higher mutation rates lead to more emerging mutants and possibly
            more diverse arrays but too high of a mutation rate leads to clonal interference
            and may even be similar to the neutral case in terms of array diversity
        \item selective advantage - neutral to weak selection means more diverse arrays in the
            small deme limit, but strong selection means quick fixation of the mutant and less
            diversity on the array level
        \item epimutation rates - too slow switching means less diversity, too fast means
            complete decoherence and regeression to a normal distribution around $0.5$
    \end{itemize}
\end{itemize}

\subsection{Efficiency and memory requirements}
Apart from standard C++ libraries, the model makes use of the \texttt{boost} library for random number
generation and reading in parameters from a config file.
\begin{itemize}
    \item time complexity
    \item memory usage
    \item output files
\end{itemize}


\section{ABC workflow for inferring \texttt{methdemon} parameters}\label{section:methabc}

\subsection{Overview}
\begin{itemize}
    \item go over the \texttt{pyabc} package briefly (cite)
    \item explain the ABC workflow and parameters used
    \item discuss computational costs and efficiency
    \item discuss whether this is the best approach (can we write down a likelihood for the problem?)
\end{itemize}

\subsection{Examples}
\textbf{TO DO:} Example fit of parameters to a synthetic dataset.


\section{Discussion}
